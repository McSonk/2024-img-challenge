{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook we'll generate images to augment the dataset using a GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "from monai.transforms import LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    "from monai.data import (CacheDataset, DataLoader, Dataset, PersistentDataset,\n",
    "                        pad_list_data_collate)\n",
    "\n",
    "\n",
    "from src.handlers import Handler, OpHandler, TciaHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gam preparation\n",
    "\n",
    "First, we'll set the required code for the gam itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose3d(nz, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'Data/'\n",
    "# ...\n",
    "TCIA_IMG_SUFFIX = '_PV.nii.gz'\n",
    "TCIA_LOCATION = BASE_PATH + 'TCIA/'\n",
    "TCIA_EXCEL_NAME = 'HCC-TACE-Seg_clinical_data-V2.xlsx'\n",
    "# ...\n",
    "OP_LOCATION = BASE_PATH + 'OP/'\n",
    "NIFTI_PATH = 'OP_C+P_nifti'\n",
    "NNU_NET_PATH = 'OP_C+P_nnUnet'\n",
    "OP_EXCEL = 'OP_申請建模_1121110_20231223.xlsx'\n",
    "OP_IMG_SUFFIX = '_VENOUS_PHASE.nii.gz'\n",
    "OP_MASK_SUFFIX = '_VENOUS_PHASE_seg.nii.gz'\n",
    "OP_ID_COL_NAME = 'OP_C+P_Tumor識別碼'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: reading file...\n",
      "INFO: 105 rows in the excel file\n",
      "INFO: Removed 3 stage-d elements\n",
      "DEBUG: Classifying...\n",
      "DEBUG: Looking for paths against contents\n",
      "DEBUG: File not found: Data/TCIA/TCIA_image_PV/HCC_011_PV.nii.gz\n",
      "DEBUG: File not found: Data/TCIA/TCIA_image_PV/HCC_031_PV.nii.gz\n",
      "DEBUG: File not found: Data/TCIA/TCIA_image_PV/HCC_082_PV.nii.gz\n",
      "WARNING: 3 files not found\n",
      "DEBUG: None\n",
      "DEBUG: reading file Data/OP/OP_申請建模_1121110_20231223.xlsx\n",
      "INFO: 200 rows in the excel file\n",
      "INFO: Removed 55 stage-d elements\n",
      "DEBUG: Classifying...\n",
      "DEBUG: Looking for paths against contents\n",
      "DEBUG: Searching for mismatch on files vs excel data...\n",
      "DEBUG: Returning new dataframe\n",
      "DEBUG: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   99 non-null     object\n",
      " 1   img     99 non-null     object\n",
      " 2   mask    99 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   244 non-null    object\n",
      " 1   img     244 non-null    object\n",
      " 2   mask    244 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "global_handler = Handler()\n",
    "\n",
    "tcia = TciaHandler(TCIA_LOCATION, TCIA_IMG_SUFFIX, TCIA_EXCEL_NAME)\n",
    "global_handler.add_source(tcia)\n",
    "\n",
    "op = OpHandler(OP_LOCATION, NIFTI_PATH, NNU_NET_PATH, OP_IMG_SUFFIX, OP_MASK_SUFFIX, OP_EXCEL, OP_ID_COL_NAME)\n",
    "global_handler.add_source(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data/TCIA/TCIA_image_PV/HCC_001_PV.nii.gz</td>\n",
       "      <td>Data/TCIA/TCIA_results_phase_PV/HCC_001_PV.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data/TCIA/TCIA_image_PV/HCC_002_PV.nii.gz</td>\n",
       "      <td>Data/TCIA/TCIA_results_phase_PV/HCC_002_PV.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data/TCIA/TCIA_image_PV/HCC_003_PV.nii.gz</td>\n",
       "      <td>Data/TCIA/TCIA_results_phase_PV/HCC_003_PV.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Data/TCIA/TCIA_image_PV/HCC_004_PV.nii.gz</td>\n",
       "      <td>Data/TCIA/TCIA_results_phase_PV/HCC_004_PV.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Data/TCIA/TCIA_image_PV/HCC_005_PV.nii.gz</td>\n",
       "      <td>Data/TCIA/TCIA_results_phase_PV/HCC_005_PV.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                        img  \\\n",
       "0     0  Data/TCIA/TCIA_image_PV/HCC_001_PV.nii.gz   \n",
       "1     2  Data/TCIA/TCIA_image_PV/HCC_002_PV.nii.gz   \n",
       "2     2  Data/TCIA/TCIA_image_PV/HCC_003_PV.nii.gz   \n",
       "3     1  Data/TCIA/TCIA_image_PV/HCC_004_PV.nii.gz   \n",
       "4     2  Data/TCIA/TCIA_image_PV/HCC_005_PV.nii.gz   \n",
       "\n",
       "                                                mask  \n",
       "0  Data/TCIA/TCIA_results_phase_PV/HCC_001_PV.nii.gz  \n",
       "1  Data/TCIA/TCIA_results_phase_PV/HCC_002_PV.nii.gz  \n",
       "2  Data/TCIA/TCIA_results_phase_PV/HCC_003_PV.nii.gz  \n",
       "3  Data/TCIA/TCIA_results_phase_PV/HCC_004_PV.nii.gz  \n",
       "4  Data/TCIA/TCIA_results_phase_PV/HCC_005_PV.nii.gz  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = global_handler.df\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys = ['class', 'mask']\n",
    "\n",
    "data_dict = df[data_keys].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: required package for reader nrrdreader is not installed, or the version doesn't match requirement.\n"
     ]
    }
   ],
   "source": [
    "_transforms = transforms.Compose([\n",
    "    LoadImaged(keys=data_keys),\n",
    "    EnsureChannelFirstd(keys=data_keys),\n",
    "    ScaleIntensityd(keys=data_keys),\n",
    "    ToTensord(keys=data_keys)\n",
    "])\n",
    "\n",
    "ds = Dataset(\n",
    "    data=data_dict,\n",
    "    transform=_transforms,\n",
    "    # cache_rate=1.0,\n",
    "    # num_workers=num_workers,\n",
    "    # cache_dir=BASE_PATH + 'cache'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sizes for the train and test sets\n",
    "train_size = int(0.8 * len(df))  # 80% for training\n",
    "test_size = len(df) - train_size  # Remaining 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = random_split(ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    collate_fn=pad_list_data_collate\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    collate_fn=pad_list_data_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nz = 100  # Size of z latent vector (i.e. size of generator input)\n",
    "num_epochs = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
