{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zsp7EkAU-OER"},"outputs":[],"source":["import os\n","import glob\n","import re\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"markdown","metadata":{"id":"ZkmDbyYC-OEW"},"source":["## Load Data\n","Remember to change the path to your own path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuOMo112-OEY","outputId":"5843b3da-dc24-4254-9de6-a0852eee077d"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------TCIA dataset--------------\n","train_files:  99\n","PV_images:  99\n","PV_masks:  99\n","Label: 0, Count: 11\n","Label: 1, Count: 23\n","Label: 2, Count: 65\n","Total count of labels: 99\n","--------------OP dataset--------------\n","train_files_2:  145\n","PV_images:  145\n","PV_masks:  145\n","Label: 0, Count: 76\n","Label: 1, Count: 55\n","Label: 2, Count: 14\n","Total count of labels: 145\n"]}],"source":["# Code for TCIA dataset\n","def PV_raw_TCIA(image_path):\n","    PV_images = sorted(glob.glob(os.path.join(image_path, \"*_PV.nii.gz\")))\n","    return PV_images\n","\n","def PV_mask_TCIA(mask_path):\n","    PV_masks = sorted(glob.glob(os.path.join(mask_path,  \"*_PV.nii.gz\")))\n","    return PV_masks\n","\n","# Code for OP dataset\n","def PV_raw_OP(image_path):\n","    PV_images = sorted(glob.glob(os.path.join(image_path, \"*.nii.gz\")))\n","    return PV_images\n","\n","def PV_mask_OP(mask_path):\n","    PV_masks = sorted(glob.glob(os.path.join(mask_path,  \"*.nii.gz\")))\n","    return PV_masks\n","\n","def load_BCLC_label_OP(clinical_data_path):\n","    clinical_df = pd.read_excel(clinical_data_path, sheet_name='202211112RINC建模申請-上繳用')\n","    clinical_df = clinical_df.dropna(subset=['BCLC'])\n","    clinical_df = clinical_df[clinical_df['BCLC'] != 'Pending']\n","    clinical_df = clinical_df[clinical_df['BCLC'] != 'D']\n","    # 濾掉clinical_df資料\n","    condition = clinical_df['OP_C+P_Tumor識別碼'].str.contains('OP_0117|OP_0277|OP_0003')\n","    clinical_df = clinical_df[~condition]\n","\n","    # remove OP_0093\n","    clinical_df = clinical_df[clinical_df['OP_C+P_Tumor識別碼'] != 'OP_0093']\n","\n","    ids = np.array(clinical_df['OP_C+P_Tumor識別碼'])\n","    pattern = re.compile(r'OP_(\\d+)')\n","    ids = [re.search(pattern, s).group(0) if re.search(pattern, s) else None for s in ids]\n","\n","    mapping = {'0': 0, 'A': 0, 'B': 1, 'C': 2}\n","    labels = np.array(clinical_df['BCLC'].replace(mapping))\n","\n","    return ids, labels\n","\n","def prepare_data_all():\n","    #TODO: change the path to your own path\n","    image_path = \"/home/hpyu/MOHW/test/TCIA_image_PV\"\n","    mask_path = \"/home/hpyu/MOHW/test/TCIA_results_phase_PV\"\n","    clinical_data_path = \"/home/hpyu/MOHW/data/HCC-TACE-Seg_clinical_data-V2.xlsx\"\n","    PV_images = PV_raw_TCIA(image_path)\n","    PV_masks = PV_mask_TCIA(mask_path)\n","    clinical_df = pd.read_excel(clinical_data_path, sheet_name='data table')\n","    pattern = r'HCC_(\\d+)'\n","    def extract_number(string):\n","        match = re.search(pattern, string)\n","        if match:\n","            return match.group(1)\n","        return None\n","    numbers_list = [\"HCC_\"+extract_number(image) for image in PV_images]\n","    clinical_df = clinical_df[clinical_df['TCIA_ID'].isin(numbers_list)]\n","    clinical_df['PVimg_path'] = clinical_df['TCIA_ID'].apply(lambda x: os.path.join(image_path, x+\"_PV.nii.gz\"))\n","    clinical_df['PVmask_path'] = clinical_df['TCIA_ID'].apply(lambda x: os.path.join(mask_path, x+\"_PV.nii.gz\"))\n","    clinical_df = clinical_df[clinical_df['BCLC'] != 'Stage-D']\n","    mapping = {'Stage-A': 0, 'Stage-B': 1, 'Stage-C': 2}\n","    labels = np.array(clinical_df['BCLC'].replace(mapping))\n","    PV_images = np.array(clinical_df['PVimg_path'])\n","    PV_masks = np.array(clinical_df['PVmask_path'])\n","    train_files = [\n","        {\"PVimg\": PV, \"PVmask\": PV_mask ,\"label\": label}\n","        for PV, PV_mask, label in zip(PV_images, PV_masks, labels)\n","        ]\n","\n","\n","    #########################################\n","    print(\"--------------TCIA dataset--------------\")\n","    print(\"train_files: \",len(train_files))\n","    print(\"PV_images: \",len(PV_images))\n","    print(\"PV_masks: \",len(PV_masks))\n","\n","    unique_labels, label_counts = np.unique(labels, return_counts=True)\n","\n","    for label, count in zip(unique_labels, label_counts):\n","        print(f\"Label: {label}, Count: {count}\")\n","\n","    total_count = np.sum(label_counts)\n","    print(\"Total count of labels:\", total_count)\n","    #########################################\n","\n","    #TODO: change the path to your own path\n","    image_path = \"/home/hpyu/MOHW/data/OP_C+P_nifti\"\n","    mask_path = \"/home/hpyu/MOHW/data/OP_C+P_nnUnet\"\n","    clinical_data_path = \"/home/hpyu/MOHW/data/OP_申請建模_1121110_20231223.xlsx\"\n","\n","    ids, labels_2 = load_BCLC_label_OP(clinical_data_path)\n","    PV_images = [path for path in PV_raw_OP(image_path) if any(id_ in path for id_ in ids)]\n","    PV_masks = [path for path in PV_mask_OP(mask_path) if any(id_[2:] in path for id_ in ids)]\n","\n","    train_files_2 = [\n","    {\"PVimg\": PV, \"PVmask\": PV_mask ,\"label\": label}\n","    for PV, PV_mask, label in zip(PV_images, PV_masks, labels_2)\n","    ]\n","\n","    #########################################\n","    print(\"--------------OP dataset--------------\")\n","    print(\"train_files_2: \",len(train_files_2))\n","    print(\"PV_images: \",len(PV_images))\n","    print(\"PV_masks: \",len(PV_masks))\n","\n","    unique_labels, label_counts = np.unique(labels_2, return_counts=True)\n","    for label, count in zip(unique_labels, label_counts):\n","        print(f\"Label: {label}, Count: {count}\")\n","\n","    total_count = np.sum(label_counts)\n","    print(\"Total count of labels:\", total_count)\n","    #########################################\n","\n","\n","    train_files.extend(train_files_2)\n","    labels = np.concatenate((labels, labels_2), axis=0)\n","\n","    return train_files, labels\n","\n","\n","train_files, labels = prepare_data_all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exe9qsGU-OEc"},"outputs":[],"source":["X_train, X_test, _, _ = train_test_split(train_files, labels, shuffle=True, test_size=0.4, random_state=8, stratify=labels)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}